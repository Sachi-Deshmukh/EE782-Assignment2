{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5937bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "pygame.mixer.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b532a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging for robustness (stretch goal)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.FileHandler(\"guard_log.txt\"), logging.StreamHandler()])\n",
    "\n",
    "# Configure Gemini API (replace with your key)\n",
    "genai.configure(api_key=\"AIzaSyDhBUtOZ40t0FdwPOzG0XsUgDVC9PbLSQU\")  # Get from makersuite.google.com\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')  # Free, fast model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11366a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen for speech (ASR with retry for robustness)\n",
    "def listen_for_speech(timeout=5, retries=3):\n",
    "    recognizer = sr.Recognizer()\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                logging.info(\"Listening...\")\n",
    "                audio = recognizer.listen(source, timeout=timeout)\n",
    "            text = recognizer.recognize_google(audio).lower()\n",
    "            logging.info(f\"Recognized: {text}\")\n",
    "            return text\n",
    "        except sr.WaitTimeoutError:\n",
    "            logging.warning(\"No speech detected.\")\n",
    "        except sr.UnknownValueError:\n",
    "            logging.warning(\"Could not understand audio.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ASR error: {e}\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ab339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        tts.save('response.mp3')\n",
    "        pygame.mixer.music.load('response.mp3')\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():  # Wait until playback finishes\n",
    "            pygame.time.Clock().tick(50) \n",
    "        pygame.mixer.music.unload()# Control frame rate\n",
    "        time.sleep(1)  # Extra buffer to ensure playback ends\n",
    "        os.remove('response.mp3')\n",
    "        logging.info(f\"Spoke: {text}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"TTS error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa42b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enroll trusted faces from folder\n",
    "def enroll_trusted_faces(folder_path):\n",
    "    trusted_embeddings = {}\n",
    "    try:\n",
    "        for person in os.listdir(folder_path):\n",
    "            person_path = os.path.join(folder_path, person)\n",
    "            if os.path.isdir(person_path):\n",
    "                trusted_embeddings[person] = []\n",
    "                for img_file in os.listdir(person_path):\n",
    "                    img_path = os.path.join(person_path, img_file)\n",
    "                    image = face_recognition.load_image_file(img_path)\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        trusted_embeddings[person].append(encodings[0])\n",
    "                    else:\n",
    "                        logging.warning(f\"No face found in {img_path}\")\n",
    "        np.save('trusted_embeddings.npy', trusted_embeddings)  # Save for reuse\n",
    "        logging.info(\"Enrollment complete.\")\n",
    "        return trusted_embeddings\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Enrollment error: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d8e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if trusted\n",
    "def is_trusted(face_encoding, trusted_embeddings, tolerance=0.4):\n",
    "    for person, embeds in trusted_embeddings.items():\n",
    "        if embeds:\n",
    "            distances = face_recognition.face_distance(embeds, face_encoding)\n",
    "            if np.min(distances) < tolerance:\n",
    "                return True, person\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589527d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LLM response\n",
    "def generate_response(prompt, level):\n",
    "    try:\n",
    "        full_prompt = f\"Act as a polite but firm AI room guard. Escalation level {level}/3: Respond to potential intruder. Keep short, natural, engaging. Base: {prompt}.\"\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM error: {e}\")\n",
    "        return f\"Default level {level} warning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd694e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalation logic (3 levels, creative and coherent)\n",
    "def escalate_conversation():\n",
    "    escalation_level = 1\n",
    "    while escalation_level <= 3:\n",
    "        if escalation_level == 1:\n",
    "            prompt = \"Politely ask who they are.\"\n",
    "        elif escalation_level == 2:\n",
    "            prompt = \"Firmly request they leave.\"\n",
    "        else:\n",
    "            prompt = \"Issue a stern warning or alarm.\"\n",
    "\n",
    "        response = generate_response(prompt, escalation_level)\n",
    "        speak(response)\n",
    "\n",
    "        # Listen for reply\n",
    "        reply = listen_for_speech()\n",
    "        if \"friend\" in reply or \"owner\" in reply:  # Simple de-escalation logic (enhance with LLM if needed)\n",
    "            speak(\"Verified. Welcome.\")\n",
    "            break\n",
    "\n",
    "        escalation_level += 1\n",
    "        time.sleep(1)  # Pause between levels\n",
    "\n",
    "    if escalation_level > 3:\n",
    "        speak(\"Intruder alert! Alerting authorities.\")  # Simulated alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fc4b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or enroll embeddings\n",
    "if os.path.exists('trusted_embeddings.npy'):\n",
    "    trusted_embeddings = np.load('trusted_embeddings.npy', allow_pickle=True).item()\n",
    "else:\n",
    "    trusted_embeddings = enroll_trusted_faces('trusted_faces/')\n",
    "if not trusted_embeddings:\n",
    "    logging.error(\"No trusted faces enrolled. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c38921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 18:47:56,457 - INFO - Listening...\n",
      "2025-10-03 18:48:04,502 - INFO - Recognized: guard my room\n",
      "2025-10-03 18:48:09,196 - INFO - Spoke: Guard mode activated. Monitoring room.\n",
      "2025-10-03 18:48:09,197 - INFO - Guard mode ON.\n"
     ]
    }
   ],
   "source": [
    "# Activation: Listen for command\n",
    "guard_mode = False\n",
    "while not guard_mode:\n",
    "    command = listen_for_speech()\n",
    "    if \"guard my room\" in command:\n",
    "        guard_mode = True\n",
    "        speak(\"Guard mode activated. Monitoring room.\")\n",
    "        logging.info(\"Guard mode ON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a48782",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "if not cap.isOpened():\n",
    "    logging.error(\"Webcam access failed.\")\n",
    "# else: \n",
    "#     # Display live feed to verify camera activation\n",
    "#     print(\"Webcam activated. Press 'q' to quit the live feed view.\")\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()  # Read a frame from the webcam\n",
    "#         if not ret:\n",
    "#             logging.error(\"Failed to capture frame from webcam.\")\n",
    "#             break\n",
    "#         cv2.imshow('Webcam Feed', frame)  # Display the frame in a window\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):  # Exit on 'q' key press\n",
    "#             break\n",
    "\n",
    "#     # Release the webcam and close the window\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     print(\"Webcam feed closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c776a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 18:48:18,717 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:48:18,719 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:48:22,538 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:48:22,539 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:48:26,134 - INFO - Untrusted detected. Escalating.\n",
      "2025-10-03 18:48:46,029 - INFO - Spoke: Hello there. I've detected an unscheduled presence. Could you please identify yourself?\n",
      "2025-10-03 18:48:46,074 - INFO - Listening...\n",
      "2025-10-03 18:48:53,677 - INFO - Recognized: no\n",
      "2025-10-03 18:49:14,819 - INFO - Spoke: Attention. My sensors indicate an unauthorized presence within this secured area. You are not permitted here. I require you to leave immediately.\n",
      "2025-10-03 18:49:14,863 - INFO - Listening...\n",
      "2025-10-03 18:49:38,827 - WARNING - Could not understand audio.\n",
      "2025-10-03 18:49:38,873 - INFO - Listening...\n",
      "2025-10-03 18:49:42,674 - INFO - Recognized: no\n",
      "2025-10-03 18:50:14,709 - INFO - Spoke: Intruder alert. Unauthorized presence confirmed. This is your *final* warning. Automated security lockdown is now active. The alarm is live, and human response teams are en route. Vacate these premises immediately.\n",
      "2025-10-03 18:50:14,756 - INFO - Listening...\n",
      "2025-10-03 18:50:17,702 - INFO - Recognized: no\n",
      "2025-10-03 18:50:23,309 - INFO - Spoke: Intruder alert! Alerting authorities.\n",
      "2025-10-03 18:50:27,004 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:27,006 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:30,695 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:30,696 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:34,907 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:34,909 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:38,636 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:38,638 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:42,612 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:42,614 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:46,391 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:46,392 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:50,055 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:50:50,057 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:50:50,505 - INFO - Untrusted detected. Escalating.\n",
      "2025-10-03 18:51:06,434 - INFO - Spoke: Excuse me. My records indicate you're not on the authorized manifest. Who might you be?\n",
      "2025-10-03 18:51:06,494 - INFO - Listening...\n",
      "2025-10-03 18:51:12,730 - WARNING - Could not understand audio.\n",
      "2025-10-03 18:51:12,771 - INFO - Listening...\n",
      "2025-10-03 18:51:15,386 - WARNING - Could not understand audio.\n",
      "2025-10-03 18:51:15,434 - INFO - Listening...\n",
      "2025-10-03 18:51:19,817 - INFO - Recognized: friend\n",
      "2025-10-03 18:51:23,263 - INFO - Spoke: Verified. Welcome.\n",
      "2025-10-03 18:51:27,087 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:51:27,087 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:51:30,860 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:51:30,861 - INFO - Trusted user: sachi\n",
      "2025-10-03 18:51:34,603 - INFO - Spoke: Welcome back, sachi.\n",
      "2025-10-03 18:51:34,604 - INFO - Trusted user: sachi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip frames for speed\u001b[39;00m\n\u001b[0;32m     10\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 11\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_frame, face_locations)\n\u001b[0;32m     13\u001b[0m detected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\sachi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "frame_skip = 5  # Process every 5th frame for optimization\n",
    "frame_count = 0\n",
    "while guard_mode:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Skip frames for speed\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    detected = False\n",
    "    for encoding in face_encodings:\n",
    "        detected = True\n",
    "        trusted, person = is_trusted(encoding, trusted_embeddings)\n",
    "        if trusted:\n",
    "            speak(f\"Welcome back, {person}.\")\n",
    "            logging.info(f\"Trusted user: {person}\")\n",
    "        else:\n",
    "            logging.info(\"Untrusted detected. Escalating.\")\n",
    "            escalate_conversation()\n",
    "    if not detected:\n",
    "        time.sleep(0.1)  # Brief pause if no face\n",
    "    cv2.imshow('AI Guard', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "logging.info(\"Guard mode OFF.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
