{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98fae99",
   "metadata": {},
   "source": [
    "Assignment-2: Final Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32934642",
   "metadata": {},
   "source": [
    "This snippet imports all the libraries needed for the AI Guard Agent’s core functions, which are computer vision (cv2, face_recognition), speech input/output (speech_recognition, gTTS, pygame), and AI dialogue (google.generativeai). It also sets up utilities (os, numpy, logging, time) and initializes the audio system with pygame.mixer.init() for playing voice responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5937bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import pygame\n",
    "import threading\n",
    "\n",
    "pygame.mixer.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0f7ab",
   "metadata": {},
   "source": [
    "This snippet imports modules for sending email alerts, allowing the system to compose messages (MIMEText, MIMEImage, MIMEMultipart) and send them through SMTP when suspicious activity (like an unknown person detected) occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.multipart import MIMEMultipart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c7cd0",
   "metadata": {},
   "source": [
    "This is to set up the default logging configuration for the Python logging module. After calling it, any logging calls made (logging.info(), logging.warning(), etc.) will follow the configuration defined here and all logging calls are also stored in the file guard_log.txt. This basically helps to track the code smoothly.\n",
    "Also, this snippet configures access to Google’s Gemini API using an API key and initializes the Gemini 2.5 Flash generative model. It enables the AI guard agent to generate natural, context-aware spoken responses or dialogue during interactions with people detected in the room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging for robustness (stretch goal)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.FileHandler(\"guard_log.txt\"), logging.StreamHandler()])\n",
    "\n",
    "# Configure Gemini API (replace with your key)\n",
    "genai.configure(api_key=\"AIzaSyDhBUtOZ40t0FdwPOzG0XsUgDVC9PbLSQU\")  # Get from makersuite.google.com\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')  # Free, fast model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5b18f",
   "metadata": {},
   "source": [
    "This function continuously listens to the microphone for speech, attempting up to three times for robustness. It uses Google’s Speech Recognition to convert spoken audio into lowercase text and logs results or errors. If speech isn’t detected or understood after all retries, it returns an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11366a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen for speech (ASR with retry for robustness)\n",
    "def listen_for_speech(timeout=5, retries=3):\n",
    "    recognizer = sr.Recognizer()\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                logging.info(\"Listening...\")\n",
    "                audio = recognizer.listen(source, timeout=timeout)\n",
    "            text = recognizer.recognize_google(audio).lower()\n",
    "            logging.info(f\"Recognized: {text}\")\n",
    "            return text\n",
    "        except sr.WaitTimeoutError:\n",
    "            logging.warning(\"No speech detected.\")\n",
    "        except sr.UnknownValueError:\n",
    "            logging.warning(\"Could not understand audio.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ASR error: {e}\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a24f5",
   "metadata": {},
   "source": [
    "This function converts a given text message into speech using Google Text-to-Speech (gTTS), plays the audio aloud via pygame, waits until playback finishes, then deletes the temporary audio file. It also logs the spoken message for tracking system interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        tts.save('response.mp3')\n",
    "        pygame.mixer.music.load('response.mp3')\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy(): # Wait until playback finishes\n",
    "            pygame.time.Clock().tick(50) \n",
    "        pygame.mixer.music.unload() # Control frame rate\n",
    "        time.sleep(1)  # Extra buffer to ensure playback ends\n",
    "        os.remove('response.mp3')\n",
    "        logging.info(f\"Spoke: {text}\")\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa79c4f",
   "metadata": {},
   "source": [
    "This function runs the speak() function in a separate background thread, allowing the AI guard to speak while continuing other tasks (like camera or mic monitoring) without freezing the main program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf446f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_async(text):\n",
    "    threading.Thread(target=speak, args=(text,), daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a829e",
   "metadata": {},
   "source": [
    "This function scans a given folder named 'trusted_faces', containing subfolders for each trusted person, extracts facial embeddings from their images using face_recognition, and stores them in a dictionary. It then saves these embeddings to a .npy file for later use and logs the process, enabling the agent to recognize trusted individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enroll trusted faces from folder\n",
    "def enroll_trusted_faces(folder_path):\n",
    "    trusted_embeddings = {}\n",
    "    try:\n",
    "        for person in os.listdir(folder_path):\n",
    "            person_path = os.path.join(folder_path, person)\n",
    "            if os.path.isdir(person_path):\n",
    "                trusted_embeddings[person] = []\n",
    "                for img_file in os.listdir(person_path):\n",
    "                    img_path = os.path.join(person_path, img_file)\n",
    "                    image = face_recognition.load_image_file(img_path)\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        trusted_embeddings[person].append(encodings[0])\n",
    "                    else:\n",
    "                        logging.warning(f\"No face found in {img_path}\")\n",
    "        np.save('trusted_embeddings.npy', trusted_embeddings)  # Save for reuse\n",
    "        logging.info(\"Enrollment complete.\")\n",
    "        return trusted_embeddings\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Enrollment error: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1edc23",
   "metadata": {},
   "source": [
    "This function checks whether a detected face matches any trusted person by comparing its encoding with stored embeddings using Euclidean distance. If the minimum distance is below the set tolerance (0.4), it returns True along with the person’s name; otherwise, it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if trusted\n",
    "def is_trusted(face_encoding, trusted_embeddings, tolerance=0.4):\n",
    "    for person, embeds in trusted_embeddings.items():\n",
    "        if embeds:\n",
    "            distances = face_recognition.face_distance(embeds, face_encoding)\n",
    "            if np.min(distances) < tolerance:\n",
    "                return True, person\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0542070",
   "metadata": {},
   "source": [
    "This function uses the Gemini LLM to generate a short, polite-but-firm response to a potential intruder. It includes the current escalation level in the prompt, sends it to the model, and returns the generated text; if an error occurs, it returns a default warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589527d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LLM response\n",
    "def generate_response(prompt, level):\n",
    "    try:\n",
    "        full_prompt = f\"Act as a polite but firm AI room guard. Escalation level {level}/3: Respond to potential intruder. Keep short, natural, engaging. Base: {prompt}.\"\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM error: {e}\")\n",
    "        return f\"Default level {level} warning.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0422f4a",
   "metadata": {},
   "source": [
    "This snippet loads email alert settings from a JSON file and defines a function to send an email with a subject, message, and attached image (like a captured intruder photo). It uses Gmail’s SMTP server for sending alerts when unauthorized activity is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fed1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load alert settings\n",
    "with open('alert_settings.json', 'r') as f:\n",
    "    alert_settings = json.load(f)\n",
    "\n",
    "def send_alert(subject, body, image_path):\n",
    "    if not alert_settings.get('enabled', False):\n",
    "        return\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = \"sfyashops1978@gmail.com\"  # Replace with your Gmail\n",
    "    msg['To'] = alert_settings['recipient']\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "    with open(image_path, 'rb') as img:\n",
    "        msg.attach(MIMEImage(img.read(), name=os.path.basename(image_path)))\n",
    "\n",
    "    with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "        server.starttls()\n",
    "        server.login(\"sfyashops1978@gmail.com\", \"gszs ctmq veef vqiz\")  # Use App Password for Gmail\n",
    "        server.send_message(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a85eaf",
   "metadata": {},
   "source": [
    "This function runs a 3-level verbal escalation: it generates and speaks increasingly firm prompts (via generate_response + speak), listens for a reply (listen_for_speech), and accepts simple keyword de-escalation (e.g., \"friend\"/\"owner\").\n",
    "If nobody verifies by level 3 it captures the current camera frame, saves and emails an intruder image via send_alert, logs/announces the intrusion, and cleans up the temp file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd694e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalation logic (3 levels, creative and coherent)\n",
    "def escalate_conversation():\n",
    "    escalation_level = 1\n",
    "    while escalation_level <= 3:\n",
    "        if escalation_level == 1:\n",
    "            prompt = \"Politely ask who they are.\"\n",
    "        elif escalation_level == 2:\n",
    "            prompt = \"Firmly request they leave.\"\n",
    "        else:\n",
    "            prompt = \"Issue a stern warning or alarm.\"\n",
    "\n",
    "        response = generate_response(prompt, escalation_level)\n",
    "        speak(response)\n",
    "\n",
    "        # Listen for reply\n",
    "        reply = listen_for_speech()\n",
    "        if \"friend\" in reply or \"owner\" in reply:  # Simple de-escalation logic (enhance with LLM if needed)\n",
    "            speak(\"Verified. Welcome.\")\n",
    "            break\n",
    "\n",
    "        escalation_level += 1\n",
    "        time.sleep(1)  # Pause between levels\n",
    "\n",
    "    if escalation_level > 3:\n",
    "        speak(\"Intruder alert! Alerting authorities.\")  \n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        image_path = f\"intruder_{timestamp}.jpg\"\n",
    "        cv2.imwrite(image_path, frame)  # frame from outer loop\n",
    "        send_alert(f\"Intruder Alert - {timestamp}\", \"Unrecognized person detected.\", image_path)\n",
    "        print(\"Alert sent.\")\n",
    "        os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b66c22a",
   "metadata": {},
   "source": [
    "This snippet attempts to enroll trusted faces from the 'trusted_faces/' folder. If no embeddings are found or enrollment fails, it logs an error and stops, ensuring the agent only runs with known trusted individuals enrolled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or enroll embeddings\n",
    "trusted_embeddings = enroll_trusted_faces('trusted_faces/')\n",
    "if not trusted_embeddings:\n",
    "    logging.error(\"No trusted faces enrolled. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789cd03",
   "metadata": {},
   "source": [
    "This loop continuously listens for the spoken command “guard my room.” Once detected, it activates guard mode, announces it verbally, and logs that the AI agent is now monitoring the room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c38921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation: Listen for command\n",
    "guard_mode = False\n",
    "while not guard_mode:\n",
    "    command = listen_for_speech()\n",
    "    if \"guard my room\" in command:\n",
    "        guard_mode = True\n",
    "        speak(\"Guard mode activated. Monitoring room.\")\n",
    "        logging.info(\"Guard mode ON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d40ebd",
   "metadata": {},
   "source": [
    "This snippet initializes webcam capture using OpenCV to start video monitoring, checks if the webcam is accessible, and exits with an error if not. It also sets up a face tracking system using a dictionary (face_tracker) and a counter (next_face_id) to uniquely identify detected faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a48782",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_tracker = {}\n",
    "next_face_id = 0\n",
    "cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "if not cap.isOpened():\n",
    "    logging.error(\"Webcam access failed.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3c7aa",
   "metadata": {},
   "source": [
    "This loop continuously captures webcam frames while the system is in guard mode. It processes every 5th frame to detect faces, recognizes trusted individuals, greets them, and flags unknown ones. Unrecognized faces trigger escalation dialogue and potential alerts. It also tracks faces over time, cleans inactive ones, and displays live video with labels and color-coded boxes (green = trusted, red = unknown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c776a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_skip = 5  # Process every 5th frame for optimization\n",
    "frame_count = 0\n",
    "unmatched_id = []  \n",
    "\n",
    "while guard_mode:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        logging.error(\"Failed to Capture Frame\")\n",
    "        break\n",
    "    frame_count += 1\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Skip frames for speed\n",
    "\n",
    "    try:\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        current_time = time.time()\n",
    "        detected = False\n",
    "\n",
    "        for face_loc, encoding in zip(face_locations, face_encodings):\n",
    "            detected = True\n",
    "\n",
    "            # Match existing face or assign new ID (from snippet)\n",
    "            matched_id = None\n",
    "            for face_id, data in face_tracker.items():\n",
    "                if face_recognition.compare_faces([data['encoding']], encoding, tolerance=0.4)[0]:\n",
    "                    matched_id = face_id\n",
    "                    break\n",
    "            if matched_id is None:\n",
    "                matched_id = next_face_id\n",
    "                next_face_id += 1\n",
    "                trusted, person = is_trusted(encoding, trusted_embeddings)\n",
    "                face_tracker[matched_id] = {'encoding': encoding, 'last_seen': current_time, 'trusted': trusted, 'person': person}\n",
    "\n",
    "            # Update tracking data\n",
    "            face_tracker[matched_id]['last_seen'] = current_time\n",
    "\n",
    "            # Scale back face location to original frame size\n",
    "            top, right, bottom, left = [v * 4 for v in face_loc]\n",
    "            color = (0, 255, 0) if face_tracker[matched_id]['trusted'] else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            label = f\"ID{matched_id}: {face_tracker[matched_id]['person'] or 'Unknown'}\"\n",
    "            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            if face_tracker[matched_id]['trusted']:\n",
    "                speak_async(f\"Welcome back, {face_tracker[matched_id]['person']}.\")\n",
    "                logging.info(f\"Trusted user: {face_tracker[matched_id]['person']}\")\n",
    "            else:\n",
    "                # Snippet: Untrusted persistence check\n",
    "                if matched_id not in unmatched_id:\n",
    "                    unmatched_id.append(matched_id)\n",
    "                elapsed = current_time - face_tracker[matched_id]['last_seen']\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 4)  # Thicker red box\n",
    "                speak_async(\"Unrecognized person detected\")\n",
    "                logging.warning(f\"{len(unmatched_id)} Unknown persons detected so far\")\n",
    "\n",
    "                # Original escalation logic (kept intact)\n",
    "                logging.info(\"Untrusted detected. Escalating.\")\n",
    "                escalate_conversation()\n",
    "\n",
    "        # Clean up expired faces (not seen for 5 seconds)\n",
    "        face_tracker = {id: data for id, data in face_tracker.items() if current_time - data['last_seen'] < 5}\n",
    "\n",
    "        if not detected:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Face processing error: {e}\")\n",
    "\n",
    "    cv2.imshow('AI Guard', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "logging.info(\"Guard mode OFF.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
